#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ç–µ—Å—Ç –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ client_card_analyzer.py –≤–µ—Ä—Å–∏–∏ 2.0
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ data_exporter.py

–ü–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
1. –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ test_result –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
2. –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é  
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
4. –°–æ–∑–¥–∞–Ω–∏–µ SQL-–∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î
"""

import json
import logging
import os
import sys
import shutil
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, str(Path(__file__).parent))

from client_card_analyzer import ClientCardAnalyzer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("test_comprehensive.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def prepare_test_environment():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥—ã"""
    logger.info("=== –ü–û–î–ì–û–¢–û–í–ö–ê –¢–ï–°–¢–û–í–û–ô –°–†–ï–î–´ ===")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É test_result –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    test_dir = Path("test_result")
    test_dir.mkdir(exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–∞ –≤ test_result
    source_file = "exported_data/client_data_515099352_20250820_203354.json"
    if not os.path.exists(source_file):
        logger.error(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {source_file}")
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    test_input_file = test_dir / f"input_client_data_{timestamp}.json"
    
    shutil.copy2(source_file, test_input_file)
    logger.info(f"‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã: {test_input_file}")
    
    return str(test_input_file)

def run_analysis_test(input_file):
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é"""
    logger.info("=== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–ù–ê–õ–ò–ó–ê –ö–õ–ò–ï–ù–¢–ê ===")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        analyzer = ClientCardAnalyzer()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–∞
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {input_file}")
        client_data = analyzer.load_from_json(input_file)
        
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã:")
        logger.info(f"   ID: {client_data['client_id']}")
        logger.info(f"   –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è: {client_data.get('lead_qualification', ['–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'])[0]}")
        logger.info(f"   –≠—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏: {client_data.get('funnel_stage', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        logger.info(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(client_data.get('recent_messages', []))}")
        
        # –ó–∞–ø—É—Å–∫ AI –∞–Ω–∞–ª–∏–∑–∞
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ AI –∞–Ω–∞–ª–∏–∑–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-90 —Å–µ–∫—É–Ω–¥)...")
        analysis_result = analyzer.analyze_client_card(client_data)
        
        if analysis_result:
            logger.info("‚úÖ AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ test_result
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = Path("test_result") / f"analysis_result_{client_data['client_id']}_{timestamp}.json"
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {result_file}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            show_analysis_summary(analysis_result)
            
            return str(result_file)
        else:
            logger.error("‚ùå AI –∞–Ω–∞–ª–∏–∑ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        import traceback
        logger.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return None

def show_analysis_summary(analysis_result):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    logger.info("=== –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ê–ù–ê–õ–ò–ó–ê ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã
    sections = {
        'client_qualification': '–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞',
        'funnel_stage_analysis': '–ê–Ω–∞–ª–∏–∑ —ç—Ç–∞–ø–∞ –≤–æ—Ä–æ–Ω–∫–∏', 
        'psychological_profile': '–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å',
        'activity_analysis': '–ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏',
        'conversation_gaps': '–ê–Ω–∞–ª–∏–∑ –ø–∞—É–∑ –≤ –¥–∏–∞–ª–æ–≥–µ',
        'pain_points_analysis': '–ê–Ω–∞–ª–∏–∑ –±–æ–ª–µ–π –∫–ª–∏–µ–Ω—Ç–∞',
        'interests_analysis': '–ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤',
        'return_strategy': '–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–æ–∑–≤—Ä–∞—Ç–∞',
        'next_contact_timing': '–í—Ä–µ–º—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞',
        'product_recommendations': '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤',
        'risk_assessment': '–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤',
        'strategic_recommendations': '–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'
    }
    
    for key, name in sections.items():
        if key in analysis_result:
            logger.info(f"‚úÖ {name} - –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
            if key == 'client_qualification' and isinstance(analysis_result[key], dict):
                level = analysis_result[key].get('current_level', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')
                score = analysis_result[key].get('confidence_score', 0)
                logger.info(f"   ‚îî‚îÄ –£—Ä–æ–≤–µ–Ω—å: {level} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {score})")
                
            elif key == 'psychological_profile' and isinstance(analysis_result[key], dict):
                personality = analysis_result[key].get('personality_type', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')
                motivation = analysis_result[key].get('primary_motivation', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')
                logger.info(f"   ‚îî‚îÄ –¢–∏–ø: {personality}, –ú–æ—Ç–∏–≤–∞—Ü–∏—è: {motivation}")
                
            elif key == 'next_contact_timing' and isinstance(analysis_result[key], dict):
                timing = analysis_result[key].get('recommended_timing', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ')
                logger.info(f"   ‚îî‚îÄ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –≤—Ä–µ–º—è: {timing}")
        else:
            logger.warning(f"‚ö†Ô∏è {name} - –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

def create_database_updates_parser(result_file):
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞—Ä—Å–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ SQL-–∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î"""
    logger.info("=== –°–û–ó–î–ê–ù–ò–ï –ü–ê–†–°–ï–†–ê –î–õ–Ø –û–ë–ù–û–í–õ–ï–ù–ò–Ø –ë–î ===")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        parser_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–º comprehensive test
"""

import json
import psycopg2
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_database_connection():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    import os
    from dotenv import load_dotenv
    load_dotenv()
    
    return psycopg2.connect(
        host=os.getenv('DB_HOST'),
        database=os.getenv('DB_NAME'), 
        user=os.getenv('DB_USER'),
        password=os.getenv('DB_PASSWORD'),
        port=os.getenv('DB_PORT', 5432)
    )

def parse_analysis_results(result_file: str) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑: {result_file}")
    
    with open(result_file, 'r', encoding='utf-8') as f:
        analysis_data = json.load(f)
    
    return analysis_data

def update_client_profile(client_id: str, analysis_data: Dict[str, Any], conn):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –∫–ª–∏–µ–Ω—Ç–∞ –≤ –ë–î –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –∫–ª–∏–µ–Ω—Ç–∞ {client_id}")
    
    cursor = conn.cursor()
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è
        updates = {}
        
        # –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        if 'client_qualification' in analysis_data:
            qual_data = analysis_data['client_qualification']
            if isinstance(qual_data, dict):
                updates['lead_qualification'] = qual_data.get('current_level')
                updates['qualification_confidence'] = qual_data.get('confidence_score')
        
        # –≠—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏
        if 'funnel_stage_analysis' in analysis_data:
            funnel_data = analysis_data['funnel_stage_analysis']
            if isinstance(funnel_data, dict):
                updates['funnel_stage'] = funnel_data.get('current_stage')
        
        # –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å
        if 'psychological_profile' in analysis_data:
            psych_data = analysis_data['psychological_profile']
            if isinstance(psych_data, dict):
                updates['personality_type'] = psych_data.get('personality_type')
                updates['primary_motivation'] = psych_data.get('primary_motivation')
                updates['communication_style'] = psych_data.get('communication_style')
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤
        if 'risk_assessment' in analysis_data:
            risk_data = analysis_data['risk_assessment']
            if isinstance(risk_data, dict):
                updates['churn_risk'] = risk_data.get('churn_probability')
                updates['engagement_level'] = risk_data.get('engagement_level')
        
        # –°—Ç—Ä–æ–∏–º SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if updates:
            set_clauses = []
            values = []
            
            for field, value in updates.items():
                if value is not None:
                    set_clauses.append(f"{field} = %s")
                    values.append(value)
            
            if set_clauses:
                values.append(client_id)
                sql = f"""
                UPDATE user_profiles 
                SET {', '.join(set_clauses)}, 
                    updated_at = CURRENT_TIMESTAMP,
                    analysis_data = %s
                WHERE conv_id = %s
                """
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–∫ JSON
                values.insert(-1, json.dumps(analysis_data, ensure_ascii=False))
                
                cursor.execute(sql, values)
                logger.info(f"‚úÖ –ü—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞ {client_id} –æ–±–Ω–æ–≤–ª–µ–Ω ({len(set_clauses)} –ø–æ–ª–µ–π)")
        
        conn.commit()
        
    except Exception as e:
        conn.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {e}")
        raise
    finally:
        cursor.close()

def create_reminder(client_id: str, analysis_data: Dict[str, Any], conn):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ {client_id}")
    
    cursor = conn.cursor()
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
        timing_data = analysis_data.get('next_contact_timing', {})
        strategy_data = analysis_data.get('return_strategy', {})
        
        if not isinstance(timing_data, dict) or not isinstance(strategy_data, dict):
            logger.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è")
            return
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
        recommended_timing = timing_data.get('recommended_timing', '1 –¥–µ–Ω—å')
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –¥–∞—Ç—É
        reminder_date = datetime.now()
        if '—á–∞—Å' in recommended_timing:
            hours = int(recommended_timing.split()[0])
            reminder_date += timedelta(hours=hours)
        elif '–¥–µ–Ω—å' in recommended_timing or '–¥–Ω—è' in recommended_timing:
            days = int(recommended_timing.split()[0])
            reminder_date += timedelta(days=days)
        elif '–Ω–µ–¥–µ–ª—è' in recommended_timing or '–Ω–µ–¥–µ–ª–∏' in recommended_timing:
            weeks = int(recommended_timing.split()[0])
            reminder_date += timedelta(weeks=weeks)
        else:
            reminder_date += timedelta(days=1)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 1 –¥–µ–Ω—å
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
        reminder_text = f"""ü§ñ –ê–ù–ê–õ–ò–ó –ö–õ–ò–ï–ù–¢–ê: {client_id}

üìä –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:
{strategy_data.get('recommended_actions', '–°–≤—è–∑–∞—Ç—å—Å—è —Å –∫–ª–∏–µ–Ω—Ç–æ–º')}

üí° –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:
{strategy_data.get('key_insights', '–î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –ø—Ä–æ—Ñ–∏–ª–µ')}

‚è∞ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –∫–æ–Ω—Ç–∞–∫—Ç–∞: {timing_data.get('optimal_time', '—Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã')}
"""
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ –ë–î
        sql = """
        INSERT INTO reminders (conv_id, reminder_text, reminder_date, status, created_at)
        VALUES (%s, %s, %s, 'active', CURRENT_TIMESTAMP)
        RETURNING id
        """
        
        cursor.execute(sql, (client_id, reminder_text, reminder_date))
        reminder_id = cursor.fetchone()[0]
        
        logger.info(f"‚úÖ –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ (ID: {reminder_id}, –¥–∞—Ç–∞: {reminder_date})")
        
        conn.commit()
        
    except Exception as e:
        conn.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è: {e}")
        raise
    finally:
        cursor.close()

def main(result_file: str):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
    logger.info("=== –ó–ê–ü–£–°–ö –ü–ê–†–°–ï–†–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ê–ù–ê–õ–ò–ó–ê ===")
    
    try:
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        analysis_data = parse_analysis_results(result_file)
        
        # –ü–æ–ª—É—á–∞–µ–º ID –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã—Ö
        if 'client_id' in analysis_data:
            client_id = analysis_data['client_id']
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            import re
            match = re.search(r'analysis_result_(\d+)_', result_file)
            if match:
                client_id = match.group(1)
            else:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å ID –∫–ª–∏–µ–Ω—Ç–∞")
        
        logger.info(f"ID –∫–ª–∏–µ–Ω—Ç–∞: {client_id}")
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        conn = get_database_connection()
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞
            update_client_profile(client_id, analysis_data, conn)
            
            # –°–æ–∑–¥–∞–µ–º –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ
            create_reminder(client_id, analysis_data, conn)
            
            logger.info("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            
        finally:
            conn.close()
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—Ç–µ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
        import traceback
        logger.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        raise

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python results_parser.py <—Ñ–∞–π–ª_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤>")
        sys.exit(1)
    
    main(sys.argv[1])
'''
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä—Å–µ—Ä
        parser_file = Path("test_result") / "results_parser.py"
        with open(parser_file, 'w', encoding='utf-8') as f:
            f.write(parser_content)
        
        logger.info(f"‚úÖ –ü–∞—Ä—Å–µ—Ä —Å–æ–∑–¥–∞–Ω: {parser_file}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞—Ä—Å–µ—Ä–∞
        instruction_content = f'''# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞—Ä—Å–µ—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## –û–ø–∏—Å–∞–Ω–∏–µ
–ü–∞—Ä—Å–µ—Ä `results_parser.py` –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∫–ª–∏–µ–Ω—Ç–∞.

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### 1. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
–§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: `{result_file}`

### 2. –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞
```bash
cd test_result
python results_parser.py {os.path.basename(result_file)}
```

### 3. –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –ø–∞—Ä—Å–µ—Ä
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞
- –û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ `user_profiles`
- –°–æ–∑–¥–∞–µ—Ç –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü–µ `reminders`
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–∫ JSON –≤ –ø–æ–ª–µ `analysis_data`

### 4. –û–±–Ω–æ–≤–ª—è–µ–º—ã–µ –ø–æ–ª—è –ø—Ä–æ—Ñ–∏–ª—è
- `lead_qualification` - –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
- `qualification_confidence` - —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏
- `funnel_stage` - —ç—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏
- `personality_type` - —Ç–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏
- `primary_motivation` - –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ—Ç–∏–≤–∞—Ü–∏—è
- `communication_style` - —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è
- `churn_risk` - —Ä–∏—Å–∫ –æ—Ç—Ç–æ–∫–∞
- `engagement_level` - —É—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏
- `analysis_data` - –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ (JSON)
- `updated_at` - –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è

### 5. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –≤—Ä–µ–º—è –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π AI
- –í–∫–ª—é—á–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
- –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å "active"

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Python 3.7+
- psycopg2-binary
- python-dotenv
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
'''
        
        instruction_file = Path("test_result") / "parser_instructions.md"
        with open(instruction_file, 'w', encoding='utf-8') as f:
            f.write(instruction_content)
        
        logger.info(f"‚úÖ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞: {instruction_file}")
        
        return str(parser_file)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
        return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞"""
    logger.info("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –¢–ï–°–¢–ê –ù–û–í–û–ô –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–°–¢–ò")
    logger.info("=" * 60)
    
    try:
        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥—ã
        test_input_file = prepare_test_environment()
        if not test_input_file:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ä–µ–¥—É")
            return False
        
        # 2. –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
        result_file = run_analysis_test(test_input_file)
        if not result_file:
            logger.error("–ê–Ω–∞–ª–∏–∑ –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω")
            return False
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –ë–î
        parser_file = create_database_updates_parser(result_file)
        if not parser_file:
            logger.error("–ü–∞—Ä—Å–µ—Ä –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω")
            return False
        
        # 4. –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
        logger.info("=" * 60)
        logger.info("üéâ –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        logger.info("=" * 60)
        logger.info(f"üìÅ –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {test_input_file}")
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞: {result_file}")
        logger.info(f"üîß –ü–∞—Ä—Å–µ—Ä –¥–ª—è –ë–î: {parser_file}")
        logger.info(f"üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: test_result/parser_instructions.md")
        
        logger.info("\nüî• –ì–û–¢–û–í–û –î–õ–Ø –ü–†–û–î–ê–ö–®–ï–ù–ê!")
        logger.info("–ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å client_card_analyzer.py –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í –ö–û–ú–ü–õ–ï–ö–°–ù–û–ú –¢–ï–°–¢–ï: {e}")
        import traceback
        logger.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    main()